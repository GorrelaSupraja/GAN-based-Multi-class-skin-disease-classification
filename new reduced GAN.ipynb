{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a24f3d37-2058-40b9-9f5a-159a62bf449c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "Melanocytic nevus       505\n",
      "Melanoma                330\n",
      "Basal cell carcinoma    248\n",
      "Benign keratosis        168\n",
      "Actinic keratosis       167\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the paths to your dataset\n",
    "dataset_paths = [\n",
    "    r'C:\\Users\\T 480\\NEW_ISIC - 2019\\ISIC - 2019\\test',\n",
    "    r'C:\\Users\\T 480\\NEW_ISIC - 2019\\ISIC - 2019\\train',\n",
    "    r'C:\\Users\\T 480\\NEW_ISIC - 2019\\ISIC - 2019\\val'\n",
    "]\n",
    "\n",
    "# Initialize empty lists to store full paths of filenames and corresponding classes\n",
    "full_paths = []\n",
    "classes = []\n",
    "\n",
    "# Iterate over each dataset path\n",
    "for dataset_path in dataset_paths:\n",
    "    # List all subdirectories in the dataset_path\n",
    "    subdirectories = [os.path.join(dataset_path, d) for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]\n",
    "    \n",
    "    # Loop through each subdirectory\n",
    "    for subdir in subdirectories:\n",
    "        # Get the class name from the last part of the path\n",
    "        class_name = os.path.basename(subdir)\n",
    "        \n",
    "        # List all files in the subdirectory\n",
    "        files = [os.path.join(subdir, f) for f in os.listdir(subdir) if os.path.isfile(os.path.join(subdir, f))]\n",
    "        \n",
    "        # Append full paths of filenames and their corresponding classes to the lists\n",
    "        full_paths.extend(files)\n",
    "        classes.extend([class_name] * len(files))\n",
    "\n",
    "# Create a dataframe from the lists\n",
    "df = pd.DataFrame({'filename': full_paths, 'class': classes})\n",
    "\n",
    "# Get class counts\n",
    "class_counts = df['class'].value_counts()\n",
    "\n",
    "# Display the class counts\n",
    "print(class_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c5632ab-49b4-40a0-80c8-665782102243",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\T 480\\NEW_ISIC - 2019\\ISIC - 2019\\tes...</td>\n",
       "      <td>Actinic keratosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\T 480\\NEW_ISIC - 2019\\ISIC - 2019\\tes...</td>\n",
       "      <td>Actinic keratosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\T 480\\NEW_ISIC - 2019\\ISIC - 2019\\tes...</td>\n",
       "      <td>Actinic keratosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\T 480\\NEW_ISIC - 2019\\ISIC - 2019\\tes...</td>\n",
       "      <td>Actinic keratosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\T 480\\NEW_ISIC - 2019\\ISIC - 2019\\tes...</td>\n",
       "      <td>Actinic keratosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1413</th>\n",
       "      <td>C:\\Users\\T 480\\NEW_ISIC - 2019\\ISIC - 2019\\val...</td>\n",
       "      <td>Melanoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>C:\\Users\\T 480\\NEW_ISIC - 2019\\ISIC - 2019\\val...</td>\n",
       "      <td>Melanoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1415</th>\n",
       "      <td>C:\\Users\\T 480\\NEW_ISIC - 2019\\ISIC - 2019\\val...</td>\n",
       "      <td>Melanoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1416</th>\n",
       "      <td>C:\\Users\\T 480\\NEW_ISIC - 2019\\ISIC - 2019\\val...</td>\n",
       "      <td>Melanoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>C:\\Users\\T 480\\NEW_ISIC - 2019\\ISIC - 2019\\val...</td>\n",
       "      <td>Melanoma</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               filename              class\n",
       "0     C:\\Users\\T 480\\NEW_ISIC - 2019\\ISIC - 2019\\tes...  Actinic keratosis\n",
       "1     C:\\Users\\T 480\\NEW_ISIC - 2019\\ISIC - 2019\\tes...  Actinic keratosis\n",
       "2     C:\\Users\\T 480\\NEW_ISIC - 2019\\ISIC - 2019\\tes...  Actinic keratosis\n",
       "3     C:\\Users\\T 480\\NEW_ISIC - 2019\\ISIC - 2019\\tes...  Actinic keratosis\n",
       "4     C:\\Users\\T 480\\NEW_ISIC - 2019\\ISIC - 2019\\tes...  Actinic keratosis\n",
       "...                                                 ...                ...\n",
       "1413  C:\\Users\\T 480\\NEW_ISIC - 2019\\ISIC - 2019\\val...           Melanoma\n",
       "1414  C:\\Users\\T 480\\NEW_ISIC - 2019\\ISIC - 2019\\val...           Melanoma\n",
       "1415  C:\\Users\\T 480\\NEW_ISIC - 2019\\ISIC - 2019\\val...           Melanoma\n",
       "1416  C:\\Users\\T 480\\NEW_ISIC - 2019\\ISIC - 2019\\val...           Melanoma\n",
       "1417  C:\\Users\\T 480\\NEW_ISIC - 2019\\ISIC - 2019\\val...           Melanoma\n",
       "\n",
       "[1418 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dd8992-de5e-4f7d-9ee5-2d242c7f235b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959c4c12-f033-41bf-b056-15bea3e2dc55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d46fd328-1de7-451c-8ac6-74fe95965e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.17.2-cp311-cp311-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.2.2 in c:\\users\\t 480\\appdata\\roaming\\python\\python311\\site-packages (from torchvision) (2.2.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.2.2->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.2.2->torchvision) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.2.2->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.2.2->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.2.2->torchvision) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.2.2->torchvision) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch==2.2.2->torchvision) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch==2.2.2->torchvision) (1.3.0)\n",
      "Downloading torchvision-0.17.2-cp311-cp311-win_amd64.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.0/1.2 MB 487.6 kB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.1/1.2 MB 1.2 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.3/1.2 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.6/1.2 MB 2.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 0.8/1.2 MB 3.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.0/1.2 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.1/1.2 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.2/1.2 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 3.0 MB/s eta 0:00:00\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.17.2\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ab6a216-93bd-485d-ae66-7720622b7528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: torch in c:\\users\\t 480\\appdata\\roaming\\python\\python311\\site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b401d904-3a14-4f21-899d-9bafeabff1d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No images found in any class directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 73\u001b[0m\n\u001b[0;32m     70\u001b[0m root_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mT 480\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mIsic\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mreduced_images\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Create a balanced dataset instance\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m balanced_dataset \u001b[38;5;241m=\u001b[39m BalancedDataset(root\u001b[38;5;241m=\u001b[39mroot_dir, transform\u001b[38;5;241m=\u001b[39mtransform)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Create a DataLoader for the balanced dataset\u001b[39;00m\n\u001b[0;32m     76\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(balanced_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 33\u001b[0m, in \u001b[0;36mBalancedDataset.__init__\u001b[1;34m(self, root, transform)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_counts[\u001b[38;5;28mcls\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(cls_images)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_counts) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 33\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo images found in any class directory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     35\u001b[0m max_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_counts\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mValueError\u001b[0m: No images found in any class directory"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "manual_seed = 999\n",
    "torch.manual_seed(manual_seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class BalancedDataset(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.classes = [d for d in os.listdir(root) if os.path.isdir(os.path.join(root, d))]\n",
    "\n",
    "        self.class_counts = {}\n",
    "        for cls in self.classes:\n",
    "            cls_dir = os.path.join(root, cls)\n",
    "            cls_images = [img for img in os.listdir(cls_dir)]\n",
    "            if len(cls_images) == 0:\n",
    "                print(f\"No images found in directory: {cls_dir}\")\n",
    "            else:\n",
    "                self.class_counts[cls] = len(cls_images)\n",
    "\n",
    "        if len(self.class_counts) == 0:\n",
    "            raise ValueError(\"No images found in any class directory\")\n",
    "\n",
    "        max_count = max(self.class_counts.values())\n",
    "\n",
    "        self.samples = []\n",
    "        for cls, count in self.class_counts.items():\n",
    "            cls_dir = os.path.join(root, cls)\n",
    "            cls_images = [img for img in os.listdir(cls_dir)]\n",
    "            self.samples.extend([(cls, img) for img in np.random.choice(cls_images, max_count, replace=True)])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        cls, img_name = self.samples[index]\n",
    "        img_path = os.path.join(self.root, cls, img_name)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "\n",
    "# Define Generator and Discriminator architectures\n",
    "# Code for Generator and Discriminator can be added here\n",
    "\n",
    "# Define the training loop\n",
    "# Code for training loop can be added here\n",
    "\n",
    "# Define the transformations for the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.CenterCrop(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "# Set the root directory of your dataset\n",
    "root_dir = r\"C:\\Users\\T 480\\Isic\\reduced_images\"\n",
    "\n",
    "# Create a balanced dataset instance\n",
    "balanced_dataset = BalancedDataset(root=root_dir, transform=transform)\n",
    "\n",
    "# Create a DataLoader for the balanced dataset\n",
    "dataloader = DataLoader(balanced_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "# Train your DCGAN using the DataLoader\n",
    "\n",
    "# Optionally, you can visualize generated images during training\n",
    "\n",
    "# Once trained, you can use the Generator to generate synthetic samples for the underrepresented classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a26f89-2f0b-4396-830a-e6063ad89e48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08d1e40f-c86d-4146-a677-94f237a2983a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           File_Path              Class\n",
      "0  C:\\Users\\T 480\\NEW_ISIC - 2019\\new2019\\Actinic...  Actinic keratosis\n",
      "1  C:\\Users\\T 480\\NEW_ISIC - 2019\\new2019\\Actinic...  Actinic keratosis\n",
      "2  C:\\Users\\T 480\\NEW_ISIC - 2019\\new2019\\Actinic...  Actinic keratosis\n",
      "3  C:\\Users\\T 480\\NEW_ISIC - 2019\\new2019\\Actinic...  Actinic keratosis\n",
      "4  C:\\Users\\T 480\\NEW_ISIC - 2019\\new2019\\Actinic...  Actinic keratosis\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory path\n",
    "directory = r'C:\\Users\\T 480\\NEW_ISIC - 2019\\new2019'\n",
    "\n",
    "# Initialize lists to store data\n",
    "file_paths = []\n",
    "classes = []\n",
    "\n",
    "# Traverse through the directory\n",
    "for root, dirs, files in os.walk(directory):\n",
    "    # Extract class name from the current directory\n",
    "    class_name = os.path.basename(root)\n",
    "    \n",
    "    # Iterate through files\n",
    "    for file in files:\n",
    "        # Append file path\n",
    "        file_paths.append(os.path.join(root, file))\n",
    "        # Append class\n",
    "        classes.append(class_name)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({'File_Path': file_paths, 'Class': classes})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbbddbe9-14f4-4944-83ee-ccb2d6279cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "Melanocytic nevus       505\n",
      "Melanoma                330\n",
      "Basal cell carcinoma    248\n",
      "Benign keratosis        168\n",
      "Actinic keratosis       167\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory path\n",
    "directory = r'C:\\Users\\T 480\\NEW_ISIC - 2019\\new2019'\n",
    "\n",
    "# Initialize lists to store data\n",
    "file_paths = []\n",
    "classes = []\n",
    "\n",
    "# Traverse through the directory\n",
    "for root, dirs, files in os.walk(directory):\n",
    "    # Extract class name from the current directory\n",
    "    class_name = os.path.basename(root)\n",
    "    \n",
    "    # Iterate through files\n",
    "    for file in files:\n",
    "        # Append file path\n",
    "        file_paths.append(os.path.join(root, file))\n",
    "        # Append class\n",
    "        classes.append(class_name)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({'File_Path': file_paths, 'Class': classes})\n",
    "\n",
    "# Get class counts\n",
    "class_counts = df['Class'].value_counts()\n",
    "\n",
    "# Display class counts\n",
    "print(class_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fb4724c-1ebb-4eae-957d-2c8c592aef05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Path</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\T 480\\NEW_ISIC - 2019\\new2019\\Actinic...</td>\n",
       "      <td>Actinic keratosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\T 480\\NEW_ISIC - 2019\\new2019\\Actinic...</td>\n",
       "      <td>Actinic keratosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\T 480\\NEW_ISIC - 2019\\new2019\\Actinic...</td>\n",
       "      <td>Actinic keratosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\T 480\\NEW_ISIC - 2019\\new2019\\Actinic...</td>\n",
       "      <td>Actinic keratosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\T 480\\NEW_ISIC - 2019\\new2019\\Actinic...</td>\n",
       "      <td>Actinic keratosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1413</th>\n",
       "      <td>C:\\Users\\T 480\\NEW_ISIC - 2019\\new2019\\Melanom...</td>\n",
       "      <td>Melanoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>C:\\Users\\T 480\\NEW_ISIC - 2019\\new2019\\Melanom...</td>\n",
       "      <td>Melanoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1415</th>\n",
       "      <td>C:\\Users\\T 480\\NEW_ISIC - 2019\\new2019\\Melanom...</td>\n",
       "      <td>Melanoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1416</th>\n",
       "      <td>C:\\Users\\T 480\\NEW_ISIC - 2019\\new2019\\Melanom...</td>\n",
       "      <td>Melanoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>C:\\Users\\T 480\\NEW_ISIC - 2019\\new2019\\Melanom...</td>\n",
       "      <td>Melanoma</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              File_Path              Class\n",
       "0     C:\\Users\\T 480\\NEW_ISIC - 2019\\new2019\\Actinic...  Actinic keratosis\n",
       "1     C:\\Users\\T 480\\NEW_ISIC - 2019\\new2019\\Actinic...  Actinic keratosis\n",
       "2     C:\\Users\\T 480\\NEW_ISIC - 2019\\new2019\\Actinic...  Actinic keratosis\n",
       "3     C:\\Users\\T 480\\NEW_ISIC - 2019\\new2019\\Actinic...  Actinic keratosis\n",
       "4     C:\\Users\\T 480\\NEW_ISIC - 2019\\new2019\\Actinic...  Actinic keratosis\n",
       "...                                                 ...                ...\n",
       "1413  C:\\Users\\T 480\\NEW_ISIC - 2019\\new2019\\Melanom...           Melanoma\n",
       "1414  C:\\Users\\T 480\\NEW_ISIC - 2019\\new2019\\Melanom...           Melanoma\n",
       "1415  C:\\Users\\T 480\\NEW_ISIC - 2019\\new2019\\Melanom...           Melanoma\n",
       "1416  C:\\Users\\T 480\\NEW_ISIC - 2019\\new2019\\Melanom...           Melanoma\n",
       "1417  C:\\Users\\T 480\\NEW_ISIC - 2019\\new2019\\Melanom...           Melanoma\n",
       "\n",
       "[1418 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927a7e58-e44c-48dd-bc80-734733bc3e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1418 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define the architecture for the generator\n",
    "def build_generator(latent_dim):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(128, input_dim=latent_dim))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dense(256))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dense(512))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dense(784, activation='tanh'))\n",
    "    model.add(layers.Reshape((28, 28, 1)))\n",
    "    return model\n",
    "\n",
    "# Define the architecture for the discriminator\n",
    "def build_discriminator():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Flatten(input_shape=(28, 28, 1)))\n",
    "    model.add(layers.Dense(512))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dense(256))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "# Define the GAN model\n",
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    model = models.Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    return model\n",
    "\n",
    "# Define the training loop\n",
    "def train_gan(generator, discriminator, gan, data_generator, latent_dim, epochs=100, batch_size=128):\n",
    "    for epoch in range(epochs):\n",
    "        for _ in range(len(data_generator)):\n",
    "            # Get batch of real images\n",
    "            real_images, _ = next(data_generator)\n",
    "\n",
    "            # Generate batch of fake images\n",
    "            noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "            fake_images = generator.predict(noise)\n",
    "\n",
    "            # Train discriminator\n",
    "            discriminator.trainable = True\n",
    "            d_loss_real = discriminator.train_on_batch(real_images, np.ones((batch_size, 1)))\n",
    "            d_loss_fake = discriminator.train_on_batch(fake_images, np.zeros((batch_size, 1)))\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # Train generator\n",
    "            noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "            discriminator.trainable = False\n",
    "            g_loss = gan.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "\n",
    "            # Print the progress\n",
    "            print(f\"Epoch {epoch + 1}, D Loss: {d_loss}, G Loss: {g_loss}\")\n",
    "\n",
    "# Define your data directory\n",
    "data_dir = r\"C:\\Users\\T 480\\NEW_ISIC - 2019\\new2019\"\n",
    "\n",
    "# Set hyperparameters\n",
    "latent_dim = 100\n",
    "epochs = 100\n",
    "batch_size = 128\n",
    "\n",
    "# Create an ImageDataGenerator for data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Load and augment your data\n",
    "data_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(28, 28),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Build and compile the discriminator\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Build the generator\n",
    "generator = build_generator(latent_dim)\n",
    "\n",
    "# Build the GAN model\n",
    "gan = build_gan(generator, discriminator)\n",
    "gan.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Train the GAN\n",
    "train_gan(generator, discriminator, gan, data_generator, latent_dim, epochs, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cc362c-2554-4c42-a733-d7f48652a81b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
